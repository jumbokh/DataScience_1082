{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "immp-som.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix_tbagzKB_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pylab as pl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TXzrzS7Kj7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SOM(object):\n",
        "    def __init__(self, X, output, iteration, batch_size):\n",
        "        \"\"\"\n",
        "        :param X:  形状是N*D， 输入样本有N个,每个D维\n",
        "        :param output: (n,m)一个元组，为输出层的形状是一个n*m的二维矩阵\n",
        "        :param iteration:迭代次数\n",
        "        :param batch_size:每次迭代时的样本数量\n",
        "        初始化一个权值矩阵，形状为D*(n*m)，即有n*m权值向量，每个D维\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        self.output = output\n",
        "        self.iteration = iteration\n",
        "        self.batch_size = batch_size\n",
        "        self.W = np.random.rand(X.shape[1], output[0] * output[1])\n",
        "        print (self.W.shape)\n",
        "\n",
        "    def GetN(self, t):\n",
        "        \"\"\"\n",
        "        :param t:时间t, 这里用迭代次数来表示时间\n",
        "        :return: 返回一个整数，表示拓扑距离，时间越大，拓扑邻域越小\n",
        "        \"\"\"\n",
        "        a = min(self.output)\n",
        "        return int(a-float(a)*t/self.iteration)\n",
        "\n",
        "    def Geteta(self, t, n):\n",
        "        \"\"\"\n",
        "        :param t: 时间t, 这里用迭代次数来表示时间\n",
        "        :param n: 拓扑距离\n",
        "        :return: 返回学习率，\n",
        "        \"\"\"\n",
        "        return np.power(np.e, -n)/(t+2)\n",
        "\n",
        "    def updata_W(self, X, t, winner):\n",
        "        N = self.GetN(t)\n",
        "        for x, i in enumerate(winner):\n",
        "            to_update = self.getneighbor(i[0], N)\n",
        "            for j in range(N+1):\n",
        "                e = self.Geteta(t, j)\n",
        "                for w in to_update[j]:\n",
        "                    self.W[:, w] = np.add(self.W[:,w], e*(X[x,:] - self.W[:,w]))\n",
        "\n",
        "    def getneighbor(self, index, N):\n",
        "        \"\"\"\n",
        "        :param index:获胜神经元的下标\n",
        "        :param N: 邻域半径\n",
        "        :return ans: 返回一个集合列表，分别是不同邻域半径内需要更新的神经元坐标\n",
        "        \"\"\"\n",
        "        a, b = self.output\n",
        "        length = a*b\n",
        "        def distence(index1, index2):\n",
        "            i1_a, i1_b = index1 // a, index1 % b\n",
        "            i2_a, i2_b = index2 // a, index2 % b\n",
        "            return np.abs(i1_a - i2_a), np.abs(i1_b - i2_b)\n",
        "\n",
        "        ans = [set() for i in range(N+1)]\n",
        "        for i in range(length):\n",
        "            dist_a, dist_b = distence(i, index)\n",
        "            if dist_a <= N and dist_b <= N: ans[max(dist_a, dist_b)].add(i)\n",
        "        return ans\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        train_Y:训练样本与形状为batch_size*(n*m)\n",
        "        winner:一个一维向量，batch_size个获胜神经元的下标\n",
        "        :return:返回值是调整后的W\n",
        "        \"\"\"\n",
        "        count = 0\n",
        "        while self.iteration > count:\n",
        "            train_X = self.X[np.random.choice(self.X.shape[0], self.batch_size)]\n",
        "            normal_W(self.W)\n",
        "            normal_X(train_X)\n",
        "            train_Y = train_X.dot(self.W)\n",
        "            winner = np.argmax(train_Y, axis=1).tolist()\n",
        "            self.updata_W(train_X, count, winner)\n",
        "            count += 1\n",
        "        return self.W\n",
        "\n",
        "    def train_result(self):\n",
        "        normal_X(self.X)\n",
        "        train_Y = self.X.dot(self.W)\n",
        "        winner = np.argmax(train_Y, axis=1).tolist()\n",
        "        print (winner)\n",
        "        return winner\n",
        "\n",
        "    def normal_X(X):\n",
        "        \"\"\"\n",
        "        :param X:二维矩阵，N*D，N个D维的数据\n",
        "        :return: 将X归一化的结果\n",
        "        \"\"\"\n",
        "        N, D = X.shape\n",
        "        for i in range(N):\n",
        "            temp = np.sum(np.multiply(X[i], X[i]))\n",
        "            X[i] /= np.sqrt(temp)\n",
        "        return X\n",
        "    def normal_W(W):\n",
        "        \"\"\"\n",
        "        :param W:二维矩阵，D*(n*m)，D个n*m维的数据\n",
        "        :return: 将W归一化的结果\n",
        "        \"\"\"\n",
        "        for i in range(W.shape[1]):\n",
        "            temp = np.sum(np.multiply(W[:,i], W[:,i]))\n",
        "            W[:, i] /= np.sqrt(temp)\n",
        "        return W\n",
        "\n",
        "#画图\n",
        "    def draw(C):\n",
        "        colValue = ['r', 'y', 'g', 'b', 'c', 'k', 'm']\n",
        "        for i in range(len(C)):\n",
        "            coo_X = []    #x坐标列表\n",
        "            coo_Y = []    #y坐标列表\n",
        "            for j in range(len(C[i])):\n",
        "                coo_X.append(C[i][j][0])\n",
        "                coo_Y.append(C[i][j][1])\n",
        "            pl.scatter(coo_X, coo_Y, marker='x', color=colValue[i%len(colValue)], label=i)\n",
        "\n",
        "        pl.legend(loc='upper right')\n",
        "        pl.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xn6T21LY8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#数据集：每三个是一组分别是西瓜的编号，密度，含糖量\n",
        "data = \"\"\"\n",
        "1,0.697,0.46,2,0.774,0.376,3,0.634,0.264,4,0.608,0.318,5,0.556,0.215,\n",
        "6,0.403,0.237,7,0.481,0.149,8,0.437,0.211,9,0.666,0.091,10,0.243,0.267,\n",
        "11,0.245,0.057,12,0.343,0.099,13,0.639,0.161,14,0.657,0.198,15,0.36,0.37,\n",
        "16,0.593,0.042,17,0.719,0.103,18,0.359,0.188,19,0.339,0.241,20,0.282,0.257,\n",
        "21,0.748,0.232,22,0.714,0.346,23,0.483,0.312,24,0.478,0.437,25,0.525,0.369,\n",
        "26,0.751,0.489,27,0.532,0.472,28,0.473,0.376,29,0.725,0.445,30,0.446,0.459\"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E1LVsVNLdfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = data.split(',')\n",
        "dataset = np.mat([[float(a[i]), float(a[i+1])] for i in range(1, len(a)-1, 3)])\n",
        "dataset_old = dataset.copy()\n",
        "\n",
        "som = SOM(dataset, (5, 5), 1, 30)\n",
        "som.train()\n",
        "res = som.train_result()\n",
        "classify = {}\n",
        "for i, win in enumerate(res):\n",
        "    if not classify.get(win[0]):\n",
        "        classify.setdefault(win[0], [i])\n",
        "    else:\n",
        "        classify[win[0]].append(i)\n",
        "C = []#未归一化的数据分类结果\n",
        "D = []#归一化的数据分类结果\n",
        "for i in classify.values():\n",
        "    C.append(dataset_old[i].tolist())\n",
        "    D.append(dataset[i].tolist())\n",
        "draw(C)\n",
        "draw(D)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}