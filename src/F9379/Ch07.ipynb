{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 程式 7.1 序列式 (Sequential)  v.s Keras 函數式 API："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers, Input\n",
    "\n",
    "seq_model = Sequential()\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\t\t\t\t\t   #1...\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "input_tensor = Input(shape=(64,))   #← 建立一個初始張量\n",
    "\n",
    "# 將初始張量傳入 Dense 層得到輸出張量 x\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    " \n",
    "# 再將第一層的結果 x 傳入第 2 個 Dense 層得到輸出張量 y                2...\n",
    "y = layers.Dense(32, activation='relu')(x) \n",
    "\n",
    "# 再將第二層的結果 y 傳入最後一個 Dense 層得到最後的輸出張量 output_tensor\n",
    "output_tensor = layers.Dense(10, activation='softmax')(y) \n",
    "\n",
    "# Model 類別 \"用\" 初始的輸入張量和最後的輸出張量來得到模型物件\n",
    "model = Model(input_tensor, output_tensor)\n",
    "model.summary()     # 來看看模型摘要吧！\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 程式 7.2 以函數式 API 實作雙輸入問答模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\t\t\t\t\t\t #↓1...                   #↓2...\n",
    "text_input = Input(shape=(None, ), dtype='int32', name='text') \n",
    "embedded_text = layers.Embedding(text_vocabulary_size, 64)(text_input) #← 3...\n",
    "print(embedded_text.shape)  \t#→ (?, ?, 64)\n",
    "encoded_text = layers.LSTM(32)(embedded_text) #← 4...\n",
    "print(encoded_text.shape)  #\t→ (?, 32)\n",
    "\n",
    "question_input = Input(shape=(None, ), dtype='int32', name='question')\n",
    "embedded_question = layers.Embedding(question_vocabulary_size, 32)(question_input) #5..\n",
    "print(embedded_question.shape)  \t#→ (?, ?, 32)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "print(encoded_question.shape)  \t#→ (?, 16)\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t#↓6...\n",
    "concatenated = layers.concatenate([encoded_question, encoded_text], axis=-1) \n",
    "print(concatenated.shape)  #→ (?, 48)\n",
    "\n",
    "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated) #← 7...\n",
    "print(answer.shape)  #→ (?, 500) \n",
    "\n",
    "model = Model([text_input, question_input], answer) #← 8...\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "#1. shape = (None, ) 代表不限定張量的 shape 大小, 所以文字輸入可以是可變長度的整數序列。\n",
    "#2. 請注意, 可以選擇是否為輸入命名, 原因為下面程式 7.2 中的訓練方法 2。\n",
    "#3. 將輸入送進嵌入層, 編碼成大小 64 的文字嵌入向量 (處理 「參考文字」輸入)。\n",
    "#4. 再透過 LSTM 層將向量序列編碼成單一個向量\n",
    "#5. 處理「問題」輸入的流程 (與處理「參考文字」輸入的流程相同)\n",
    "#6. 串接編碼後的「問題」和「參考文字」資料 (向量), 將兩份資料合而為一。axis 參數為 -1 代表以輸入的最後一個軸進行串接。\n",
    "#7. 最後增加一個 Dense層 (softmax分類器), 將串接向量送入, 輸出模型的結果張量 answer。\n",
    "#8. 在模型實例化時, 因為有兩個輸入, 所以將它們組成一個 list 一起做為輸入, 而輸出為 answer。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 程式 7.3 將資料以兩種方式 (list、dict) 傳遞到多輸入模型進行訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "# 產生 text 資料：1000 筆, 每筆 100 個字 (數字)\n",
    "text = np.random.randint(1, text_vocabulary_size, \n",
    "                         size=(num_samples, max_length))\n",
    "#  [  [2, 15, 8000,..... 共 100 個], [],....共 1000 筆  ]  \n",
    "#      ↑   ↑    ↑         \n",
    "#     產生 1 ~ 10000 (text_vocabulary_size) 區間的數字 \n",
    "print(text.shape)       # (1000, 100)\n",
    "\n",
    "# 產生 question 資料, 與上面 text 產生方式相同\n",
    "question = np.random.randint(1, question_vocabulary_size, \n",
    "                             size=(num_samples, max_length))\n",
    "print(question.shape)   # (1000, 100)\n",
    "\n",
    "# 產生 answers 資料, 需為 One-hot 編碼, 共 1000 個正確答案\n",
    "answers = np.random.randint(0, 1, size=(num_samples, \n",
    "                                        answer_vocabulary_size))\n",
    "#  [  [0, 1, 1,..... 共 100 個], [],.... 共 1000 筆  ]\n",
    "#      ↑  ↑  ↑         \n",
    "#     產生 0 ~ 1 的數字 \n",
    "# 此為分類器要用的 One-encoding 編碼答案    \n",
    "print(answers.shape)    # (1000, 500)\n",
    "\n",
    "# 訓練方法 1：使用 list 方式送入資料進行擬合 \n",
    "#model.fit([text, question], answers, epochs=10, batch_size=128)\n",
    "# 訓練方法 2：使用 dict 方式送入資料進行擬合, 鍵為 Input 層的名稱, 值為 Numpy 資料\n",
    "model.fit({'text': text, 'question': question}, answers, epochs=10,  batch_size=128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 程式 7.4 以函數式 API 實作三個輸出結果模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import layers, Input\n",
    "from keras.models import Model\n",
    "\n",
    "vocabulary_size = 50000 \t#← 文章大小\n",
    "num_income_groups = 10 \t#← 將收入分成 10 群\n",
    "                            \n",
    "                          # ↓不限定輸入向量的 shape 大小\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts') \n",
    "\n",
    "# 用函數式 API 將輸入向量傳入 Embedding 層, 得到維度 256 的嵌入向量\n",
    "embedding_posts = layers.Embedding(vocabulary_size, 256)(posts_input)\n",
    "print(embedding_posts.shape)   # ← (?, ?, 256)\n",
    "\n",
    "# 以下以函數式 API 將嵌入向量傳入一層層之中進行處理\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embedding_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)  \n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "print(x.shape)  #← 走過一連串層之後, x.shape 為 (?, 128)\n",
    "\n",
    "# 接下來將 x 向量分別送入 3 個輸出層。請注意, \n",
    "# 需為輸出層指定名稱(原因請見程式 7.5 中的編譯方法 2)\n",
    "\n",
    "# 預測年紀的輸出層：純量迴歸任務\n",
    "age_prediction = layers.Dense(1, name='age')(x)\n",
    "\n",
    "# 預測收入族群的輸出層多分類任務 (10 類)\n",
    "income_prediction = layers.Dense(num_income_groups, \n",
    "                                 activation='softmax', \n",
    "                                 name='income')(x)\n",
    "# 預測性別的輸出層：二元分類任務\n",
    "gender_prediction = layers.Dense(1, \n",
    "                                 activation='sigmoid', \n",
    "                                 name='gender')(x)\n",
    "\n",
    "# 用輸入向量與輸出向量實例化 Model 物件\n",
    "model = Model(posts_input, \n",
    "              [age_prediction, income_prediction, gender_prediction])\n",
    "                 #↑ 因為輸出向量有 3 個, 所以用 list 來組成\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 程式 7.5 多輸出模型的編譯選項, 指定多重損失函數, 有兩種方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 編譯方式 1 \n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss=['mse',\t\t#← (需照建立層的順序)\n",
    "                    'categorical_crossentropy', \n",
    "                    'binary_crossentropy'])\n",
    "# 編譯方式 2 \n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss={'age': 'mse',\t#← (需為輸出層指定名稱)\n",
    "                    'income': 'categorical_crossentropy', \n",
    "                    'gender': 'binary_crossentropy'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 程式 7.6 孿生 (Siamese) LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import applications\n",
    "from keras import Input\n",
    "\n",
    "# 我們使用 Xception 神經網路的卷積基底 (不包含最上層的分類器) 進行影像的特徵萃取\n",
    "xception_base = applications.Xception(weights=None, include_top=False)\n",
    "\n",
    "# 建立左、右輸入張量 (左、右鏡頭影像), 其 shape 為 (250, 250, 3), 即為 250x250 的彩色影像。\n",
    "left_input = Input(shape=(250, 250, 3))\n",
    "right_input = Input(shape=(250, 250, 3))\n",
    "\n",
    "# 呼叫相同的視覺模型兩次, 也就是將影像張量傳入 Xception 神經網路物件。\n",
    "left_features = xception_base(left_input)\n",
    "right_features = xception_base(right_input)\n",
    "\n",
    "# 萃取出的左、右影像特徵張量 shape = (?, 8, 8, 2048)\n",
    "print(left_features.shape)\n",
    "print(right_features.shape)\n",
    "\n",
    "# 串接左右影像特徵張量, shape = (?, 8, 8, 4096)\n",
    "merged_features = layers.concatenate([left_features, right_features], axis=-1)\n",
    "print(merged_features.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 程式 7.7 將使用 TensorBoard 的文字分類模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embed (Embedding)            (None, 500, 128)          256000    \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 494, 32)           28704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 291,937\n",
      "Trainable params: 291,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from keras import layers\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_features = 2000\n",
    "max_len = 500\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.Embedding(max_features, 128, input_length=max_len, name='embed'))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPool1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.GlobalMaxPool1D())\n",
    "model.add(layers.Dense(1))\n",
    "model.summary()\n",
    "# model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 程式 7.8 為 TensorBoard 紀錄檔案建立目錄 (Linux 的指令)\n",
    "### $ mkdir my_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 程式 7.9 使用 TensorBoard 回呼來訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks = [keras.callbacks.TensorBoard(log_dir='my_log_dir', \n",
    "                                         histogram_freq=1, \n",
    "                                         embeddings_freq=1)]\n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "                    epochs=20, batch_size=128, \n",
    "                    validation_split=0.2, \n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 建構輕量的深度可分離卷積神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "separable_conv2d_14 (Separab (None, 62, 62, 32)        155       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_15 (Separab (None, 60, 60, 64)        2400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_16 (Separab (None, 28, 28, 64)        4736      \n",
      "_________________________________________________________________\n",
      "separable_conv2d_17 (Separab (None, 26, 26, 128)       8896      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 128)       0         \n",
      "=================================================================\n",
      "Total params: 16,187\n",
      "Trainable params: 16,187\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "\n",
    "height = 64\n",
    "width = 64\n",
    "channels = 3\n",
    "num_classes = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.SeparableConv2D(32, 3, \n",
    "                                 activation='relu', \n",
    "                                 input_shape=(height, width, channels)))\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.MaxPool2D(2))\n",
    "\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.SeparableConv2D(128, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "# model.add(layers.SeparableConv2D(64, 3, activation='relu'))  # 怪怪的\n",
    "model.add(layers.SeparableConv2D(128, 3, activation='relu'))\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
